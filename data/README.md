# Data Directory

## Quick Start â€” Download Pre-Cleaned Data

ðŸ“¥ **[Download Cleaned Dataset (Parquet)](https://drive.google.com/drive/folders/1l_5WC5gacZAnCjZCgcSC6ZvNc4Sa2Igc?usp=sharing)**

Place the downloaded file at:
```
data/processed/newssumm_cleaned.parquet
```

ðŸ“¥ **[Download HiGS Model Checkpoint](https://drive.google.com/drive/folders/1hqYPvjdl443WFcgfs9OA-73p0U5Nusbm?usp=sharing)**

Place the downloaded `.pt` file at:
```
results/higs/best_checkpoint.pt
```

## Raw Dataset (Optional)

To run the full cleaning pipeline from scratch, place the raw Excel file here:
```
data/NewsSumm_Dataset.xlsx
```

After running the cleaning and preprocessing pipelines, the following files will be generated:

```
data/
â”œâ”€â”€ NewsSumm_Dataset.xlsx          # Original dataset (place manually)
â””â”€â”€ processed/
    â”œâ”€â”€ newssumm_cleaned.parquet   # Cleaned dataset
    â”œâ”€â”€ train.parquet              # Training split (80%)
    â”œâ”€â”€ val.parquet                # Validation split (10%)
    â”œâ”€â”€ test.parquet               # Test split (10%)
    â”œâ”€â”€ eda_distributions.png     # EDA visualizations
    â””â”€â”€ eda_compression.png       # Compression ratio plots
```

## Dataset Description

The **NewsSumm** dataset is a large-scale Indian English multi-document news summarization corpus containing ~100,000+ article-summary pairs from major Indian news sources.

**Columns:**
- `newspaper_name` â€” Source publication
- `published_date` â€” Publication date
- `headline` â€” Article headline
- `article_text` â€” Full article text
- `human_summary` â€” Human-written reference summary
- `news_category` â€” News category (politics, sports, business, etc.)
